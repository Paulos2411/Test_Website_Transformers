llms:
  - model: "CELLama"
    paper: "ğŸ“Choi et al. 2024"
    paper_link: "https://www.biorxiv.org/content/10.1101/2024.05.08.593094v1.full#ref-16"
    code: "ğŸ› GitHub"
    code_link: "https://github.com/portrai-io/CELLama"
    omic_modalities: "scRNA-seq, Spatial transcriptomics"
    pretraining_dataset: "Natural Language SBERT"
    input_embedding: "Other: Ordering with embedding of the natural language representation, additional cell annotations are added in natural language"
    architecture: "Siamese encoders (SBERT)"
    ssl_tasks: "Contrastive loss"
    supervised_tasks: "Cell type annotation"
    zero_shot_tasks: "Cell type annotation, niche cell type featuring"
  - model: "CellWhisperer"
    paper: "ğŸ“Schaefer et al. 2024"
    paper_link: "https://www.biorxiv.org/content/10.1101/2024.10.15.618501v1"
    code: "ğŸ› GitHub"
    code_link: "https://github.com/epigen/cellwhisperer"
    omic_modalities: "Bulk/scRNA-seq"
    pretraining_dataset: "Transcriptome data paired with natural language annotations"
    input_embedding: "Geneformer- and BioBERT-based embedding models (contrastively fine-tuned)"
    architecture: "Multimodal contrastive training of embedding models (CLIP) and transcriptome instruction fine-tuning of LLM (LLaVA)"
    ssl_tasks: "None"
    supervised_tasks: "Transcriptome-aware question-answering"
    zero_shot_tasks: "Reference-free cell property prediction (cell types & states, disease states, organ of cell origin, ...)"
  # ... Include all other models following the same structure
